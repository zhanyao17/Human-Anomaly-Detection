{"cells":[{"cell_type":"markdown","metadata":{"id":"PF6UGX5Ku3qx"},"source":["# Install packages"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"execution":{"iopub.execute_input":"2024-07-24T09:54:14.479084Z","iopub.status.busy":"2024-07-24T09:54:14.478724Z","iopub.status.idle":"2024-07-24T09:55:28.951850Z","shell.execute_reply":"2024-07-24T09:55:28.950660Z","shell.execute_reply.started":"2024-07-24T09:54:14.479044Z"},"id":"m0NrsHHIu15H","jupyter":{"outputs_hidden":true},"outputId":"ed4c0f48-f1fc-4dcf-9806-aa8c354afcc3","trusted":true},"outputs":[],"source":["!pip install scenic\n","!pip install einops\n","# !pip install -qq medmnist\n","!pip install --upgrade keras\n","!pip install keras-tuner\n","!pip install gdown"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T09:56:11.835116Z","iopub.status.busy":"2024-07-24T09:56:11.834191Z","iopub.status.idle":"2024-07-24T09:56:26.725814Z","shell.execute_reply":"2024-07-24T09:56:26.725025Z","shell.execute_reply.started":"2024-07-24T09:56:11.835075Z"},"id":"AuOVzsPlojIe","trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import os\n","import keras\n","from keras import layers, ops, regularizers\n","\n","import numpy as np\n","# import matplotlib.pyplot as plt\n","# import skvideo.io\n","import pandas as pd\n","import cv2\n","import os"]},{"cell_type":"markdown","metadata":{"id":"RXRBDdJ0iGor"},"source":["# Reload data from pkl"]},{"cell_type":"markdown","metadata":{"id":"s8xSfpkmjTZC"},"source":["#### Video"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T09:56:44.778566Z","iopub.status.busy":"2024-07-24T09:56:44.777525Z","iopub.status.idle":"2024-07-24T09:57:03.184187Z","shell.execute_reply":"2024-07-24T09:57:03.183177Z","shell.execute_reply.started":"2024-07-24T09:56:44.778529Z"},"id":"Gf0TDiUbiTXv","trusted":true},"outputs":[],"source":["import pickle\n","with open('/kaggle/input/3july-2-pkll/3July_2/ab_videos.pkl', 'rb') as file:\n","    loaded_vid_list = pickle.load(file)\n","ab_videos=[]\n","x=0\n","while True:\n","  try:\n","    array_a_loaded = loaded_vid_list[x]\n","    x+=1\n","    ab_videos.append(array_a_loaded)\n","  except:\n","    print('end!')\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T09:57:43.903124Z","iopub.status.busy":"2024-07-24T09:57:43.902402Z","iopub.status.idle":"2024-07-24T09:58:04.213777Z","shell.execute_reply":"2024-07-24T09:58:04.212764Z","shell.execute_reply.started":"2024-07-24T09:57:43.903093Z"},"id":"IEwZmKHmjdmH","trusted":true},"outputs":[],"source":["with open('/kaggle/input/3july-2-pkll/3July_2/nor_videos.pkl', 'rb') as file:\n","    loaded_vid_list = pickle.load(file)\n","nor_videos=[]\n","x=0\n","while True:\n","  try:\n","    array_a_loaded = loaded_vid_list[x]\n","    x+=1\n","    nor_videos.append(array_a_loaded)\n","  except:\n","    print('end!')\n","    break"]},{"cell_type":"markdown","metadata":{"id":"JUnlK1pZjSVx"},"source":["#### Dims"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T09:58:06.808379Z","iopub.status.busy":"2024-07-24T09:58:06.807998Z","iopub.status.idle":"2024-07-24T09:58:07.038108Z","shell.execute_reply":"2024-07-24T09:58:07.037236Z","shell.execute_reply.started":"2024-07-24T09:58:06.808349Z"},"id":"z-q8-BrcjDA0","trusted":true},"outputs":[],"source":["with open('/kaggle/input/3july-2-pkll/3July_2/ab_video_dims.pkl', 'rb') as file:\n","    loaded_vid_list = pickle.load(file)\n","ab_video_dims=[]\n","x=0\n","while True:\n","  try:\n","    array_a_loaded = loaded_vid_list[x]\n","    x+=1\n","    ab_video_dims.append(array_a_loaded)\n","  except:\n","    print('end!')\n","    break\n","with open('/kaggle/input/3july-2-pkll/3July_2/nor_video_dims.pkl', 'rb') as file:\n","    loaded_vid_list = pickle.load(file)\n","nor_video_dims=[]\n","x=0\n","while True:\n","  try:\n","    array_a_loaded = loaded_vid_list[x]\n","    x+=1\n","    nor_video_dims.append(array_a_loaded)\n","  except:\n","    print('end!')\n","    break"]},{"cell_type":"markdown","metadata":{"id":"wszwMvTEPIhj"},"source":["# Modelling pre-process <a class=\"anchor\"  id=\"modelpre\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T09:58:10.016481Z","iopub.status.busy":"2024-07-24T09:58:10.015815Z","iopub.status.idle":"2024-07-24T09:58:11.424628Z","shell.execute_reply":"2024-07-24T09:58:11.423514Z","shell.execute_reply.started":"2024-07-24T09:58:10.016449Z"},"id":"zzigW1BgQEjv","trusted":true},"outputs":[],"source":["human_action_dataset = np.asarray( ab_videos + nor_videos )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T09:58:12.880915Z","iopub.status.busy":"2024-07-24T09:58:12.880018Z","iopub.status.idle":"2024-07-24T09:58:12.885252Z","shell.execute_reply":"2024-07-24T09:58:12.884284Z","shell.execute_reply.started":"2024-07-24T09:58:12.880885Z"},"id":"jCPBPgCxQFjs","trusted":true},"outputs":[],"source":["# abnormal = 1\n","# normal = 0\n","labels = np.concatenate([np.ones(len(ab_videos)),np.zeros(len(nor_videos))])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T09:58:16.600498Z","iopub.status.busy":"2024-07-24T09:58:16.599825Z","iopub.status.idle":"2024-07-24T09:58:16.674166Z","shell.execute_reply":"2024-07-24T09:58:16.673207Z","shell.execute_reply.started":"2024-07-24T09:58:16.600466Z"},"id":"6W0-04c1QGeX","trusted":true},"outputs":[],"source":["ab_videos_dims_df = pd.DataFrame(ab_video_dims,columns=['frames','width','height','channel'])\n","nor_videos_dims_df = pd.DataFrame(nor_video_dims,columns=['frames','width','height','channel'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T09:58:18.480787Z","iopub.status.busy":"2024-07-24T09:58:18.480133Z","iopub.status.idle":"2024-07-24T09:58:21.180644Z","shell.execute_reply":"2024-07-24T09:58:21.179824Z","shell.execute_reply.started":"2024-07-24T09:58:18.480757Z"},"id":"mon9IlvOQHR5","trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train,X_test,y_train,y_test = train_test_split(human_action_dataset,labels,test_size=0.2,shuffle=True,random_state=42,stratify=labels)\n","X_test,X_valid,y_test,y_valid = train_test_split(X_test,y_test,test_size=0.5,shuffle=True,random_state=42)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T09:58:22.669597Z","iopub.status.busy":"2024-07-24T09:58:22.668458Z","iopub.status.idle":"2024-07-24T09:58:22.815073Z","shell.execute_reply":"2024-07-24T09:58:22.814115Z","shell.execute_reply.started":"2024-07-24T09:58:22.669552Z"},"id":"yEW_gnXRQIR5","trusted":true},"outputs":[],"source":["# Setting seed for reproducibility\n","SEED = 42\n","os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n","keras.utils.set_random_seed(SEED)"]},{"cell_type":"markdown","metadata":{"id":"IggDO_X8yTDc"},"source":["# Trans body"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T05:17:17.016965Z","iopub.status.busy":"2024-07-05T05:17:17.016024Z","iopub.status.idle":"2024-07-05T05:17:17.025451Z","shell.execute_reply":"2024-07-05T05:17:17.024629Z","shell.execute_reply.started":"2024-07-05T05:17:17.016926Z"},"id":"UX7kThCgQJa-","trusted":true},"outputs":[],"source":["# Setting seed for reproducibility\n","SEED = 77\n","os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n","tf.random.set_seed(SEED)\n","\n","# DATA\n","BATCH_SIZE = 4\n","AUTO = tf.data.AUTOTUNE\n","INPUT_SHAPE = (40, 224, 224, 3)\n","NUM_CLASSES = 2\n","\n","# OPTIMIZER\n","# LEARNING_RATE = 1e-4 #Default\n","LEARNING_RATE = 1e-4 #CHANGE THIS\n","WEIGHT_DECAY = 1e-5\n","\n","# TRAINING\n","EPOCHS = 20\n","\n","# TUBELET EMBEDDING\n","PATCH_SIZE = (8, 8, 8)\n","NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n","\n","# ViViT ARCHITECTURE\n","LAYER_NORM_EPS = 1e-6\n","PROJECTION_DIM = 64\n","NUM_HEADS = 2\n","NUM_LAYERS = 2\n","# NUM_HEADS = 4\n","# NUM_LAYERS = 4"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T09:58:32.449659Z","iopub.status.busy":"2024-07-24T09:58:32.448844Z","iopub.status.idle":"2024-07-24T09:58:46.137280Z","shell.execute_reply":"2024-07-24T09:58:46.136506Z","shell.execute_reply.started":"2024-07-24T09:58:32.449626Z"},"id":"2Zsn7XPXQK2X","trusted":true},"outputs":[],"source":["@tf.function\n","def preprocess(frames: tf.Tensor, label: tf.Tensor):\n","    \"\"\"\n","      Preprocess the frames tensors and parse the labels.\n","      This code convert the framess into float for normalization hence\n","      we should add a convert dtype code back to the model\n","    \"\"\"\n","    # Preprocess images\n","    frames = tf.image.convert_image_dtype(frames[..., tf.newaxis],  tf.float32,)\n","    # Parse label\n","    label = tf.cast(label, tf.float32)\n","    return frames, label\n","\n","\n","def prepare_dataloader(\n","    videos: np.ndarray,\n","    labels: np.ndarray,\n","    loader_type: str = \"train\",\n","    batch_size: int = BATCH_SIZE,\n","):\n","    \"\"\"Utility function to prepare the dataloader.\"\"\"\n","    dataset = tf.data.Dataset.from_tensor_slices((videos, labels))\n","\n","    if loader_type == \"train\":\n","        dataset = dataset.shuffle(BATCH_SIZE * 2)\n","\n","    dataloader = (\n","        dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n","        .batch(batch_size)\n","        .prefetch(tf.data.AUTOTUNE)\n","    )\n","    return dataloader\n","\n","# Training set\n","trainloader = prepare_dataloader(X_train, y_train, \"train\")\n","testloader = prepare_dataloader(X_test, y_test, \"test\")\n","validloader = prepare_dataloader(X_valid, y_valid, \"test\")\n","\n","# Further testing set\n","# testloader2 = prepare_dataloader(human_action_dataset, labels, \"test2\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T09:58:52.834043Z","iopub.status.busy":"2024-07-24T09:58:52.833418Z","iopub.status.idle":"2024-07-24T09:58:52.863732Z","shell.execute_reply":"2024-07-24T09:58:52.862755Z","shell.execute_reply.started":"2024-07-24T09:58:52.834009Z"},"id":"v_qv30-iQMl9","trusted":true},"outputs":[],"source":["from tensorflow.keras.utils import register_keras_serializable\n","\n","@register_keras_serializable(package=\"Custom\", name=\"TubeletEmbedding\")\n","class TubeletEmbedding(layers.Layer):\n","    def __init__(self, embed_dim, patch_size, **kwargs):\n","        super().__init__(**kwargs)\n","        self.projection = layers.Conv3D(\n","            filters=embed_dim, # embed_dim = 64\n","            kernel_size=patch_size, # patch_size = (8, 8, 8)\n","            strides=patch_size, \n","            padding=\"VALID\",\n","        )\n","        self.flatten = layers.Reshape(target_shape=(-1, embed_dim))\n","\n","    def call(self, videos):\n","        projected_patches = self.projection(videos)\n","        flattened_patches = self.flatten(projected_patches)\n","        return flattened_patches\n","\n","@register_keras_serializable(package=\"Custom\", name=\"PositionalEncoder\")\n","class PositionalEncoder(layers.Layer):\n","    def __init__(self, embed_dim, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","\n","    def build(self, input_shape):\n","        _, num_tokens, _ = input_shape # input_shape =(numVid,3920,64)\n","        self.position_embedding = layers.Embedding(\n","            input_dim=num_tokens, output_dim=self.embed_dim\n","        )\n","        self.positions = tf.range(start=0, limit=num_tokens, delta=1) # Set positions\n","\n","    def call(self, encoded_tokens):\n","        # Encode the positions and add it to the encoded tokens\n","        encoded_positions = self.position_embedding(self.positions)\n","        encoded_tokens = encoded_tokens + encoded_positions # Concat the position with it token\n","        return encoded_tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-03T05:33:49.954426Z","iopub.status.busy":"2024-07-03T05:33:49.953624Z","iopub.status.idle":"2024-07-03T05:33:49.964919Z","shell.execute_reply":"2024-07-03T05:33:49.963993Z","shell.execute_reply.started":"2024-07-03T05:33:49.954390Z"},"id":"dOWLvfqQQNzq","trusted":true},"outputs":[],"source":["# '''\n","# Params:\n","#   Added drop out layers\n","# '''\n","# def create_vivit_classifier(\n","#     tubelet_embedder,\n","#     positional_encoder,\n","#     input_shape=INPUT_SHAPE,\n","#     transformer_layers=NUM_LAYERS,\n","#     num_heads=NUM_HEADS,\n","#     embed_dim=PROJECTION_DIM,\n","#     layer_norm_eps=LAYER_NORM_EPS,\n","#     num_classes=NUM_CLASSES,\n","#     dropout_rate=0.3,\n","# ):\n","#     # Get the input layer\n","#     inputs = layers.Input(shape=input_shape)\n","#     # Create patches.\n","#     patches = tubelet_embedder(inputs)\n","#     # Encode patches.\n","#     encoded_patches = positional_encoder(patches)\n","\n","#     # Create multiple layers of the Transformer block.\n","#     for _ in range(transformer_layers):\n","#         # Layer normalization and MHSA\n","#         x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","#         attention_output = layers.MultiHeadAttention(\n","#             num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=0.1\n","#         )(x1, x1)\n","\n","#         #NOTE: Adding drop out for attention output\n","#         attention_output = layers.Dropout(dropout_rate)(attention_output)\n","\n","#         # Skip connection\n","#         x2 = layers.Add()([attention_output, encoded_patches])\n","\n","#         # Layer Normalization and MLP\n","#         x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n","#         x3 = keras.Sequential(\n","#             [\n","#                 layers.Dense(units=embed_dim * 4, activation=ops.gelu),\n","#                 layers.Dense(units=embed_dim, activation=ops.gelu),\n","#             ]\n","#         )(x3)\n","\n","#         #NOTE Dropout after MLP\n","#         x3 = layers.Dropout(dropout_rate)(x3)\n","\n","#         # Skip connection\n","#         encoded_patches = layers.Add()([x3, x2])\n","\n","#     # Layer normalization and Global average pooling.\n","#     representation = layers.LayerNormalization(epsilon=layer_norm_eps)(encoded_patches)\n","#     representation = layers.GlobalAvgPool1D()(representation)\n","\n","#     #NOTE: Optional dropout after global average pooling\n","#     representation = layers.Dropout(dropout_rate)(representation)\n","\n","#     # Classify outputs.\n","#     outputs = layers.Dense(units=num_classes, activation=\"softmax\")(representation)\n","\n","#     # Create the Keras model.\n","#     model = keras.Model(inputs=inputs, outputs=outputs)\n","#     return model"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T09:58:56.199622Z","iopub.status.busy":"2024-07-24T09:58:56.198938Z","iopub.status.idle":"2024-07-24T09:58:56.209655Z","shell.execute_reply":"2024-07-24T09:58:56.208726Z","shell.execute_reply.started":"2024-07-24T09:58:56.199587Z"},"id":"vQzCSFPxn6n_","trusted":true},"outputs":[],"source":["# Base line\n","def create_vivit_classifier(\n","    tubelet_embedder,\n","    positional_encoder,\n","    input_shape=INPUT_SHAPE,# (40, 224, 224, 3)\n","    transformer_layers=NUM_LAYERS,# num_layers = 2\n","    num_heads=NUM_HEADS, # num_heads = 2\n","    embed_dim=PROJECTION_DIM,# embed_dim = 64\n","    layer_norm_eps=LAYER_NORM_EPS, # le-6\n","    num_classes=NUM_CLASSES,# 2(normal, abnormal)\n","):\n","    # Get the input layer\n","    inputs = layers.Input(shape=input_shape)\n","    # Create patches.\n","    patches = tubelet_embedder(inputs)\n","    # Encode patches.\n","    encoded_patches = positional_encoder(patches)\n","\n","    # Create multiple layers of the Transformer block.\n","    for _ in range(transformer_layers):\n","        # Layer normalization\n","        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","\n","        # Multi-head\n","        attention_output = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=0.1 # NOTE: dropout\n","        )(x1, x1)\n","\n","        # Skip connection\n","        x2 = layers.Add()([attention_output, encoded_patches])\n","\n","        # Layer normalization \n","        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n","        \n","        # MLP\n","        x3 = keras.Sequential(\n","            [\n","                layers.Dense(units=embed_dim * 4, activation=ops.gelu),\n","                layers.Dense(units=embed_dim, activation=ops.gelu),\n","            ]\n","        )(x3)\n","\n","        # Skip connection\n","        encoded_patches = layers.Add()([x3, x2])\n","\n","    # Layer normalization and Global average pooling.\n","    representation = layers.LayerNormalization(epsilon=layer_norm_eps)(encoded_patches)\n","    representation = layers.GlobalAvgPool1D()(representation)\n","\n","    # Classify outputs.\n","    outputs = layers.Dense(units=num_classes, activation=\"softmax\")(representation)\n","\n","    # Create the Keras model.\n","    model = keras.Model(inputs=inputs, outputs=outputs)\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["# Final ViViT Model\n","NOTE: \n","1. This was run after the hyperparameter completed\n","2. Findings: Drop out rate = 0.4 & learning rate = 1e-4 had score the highes val_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T03:41:14.322731Z","iopub.status.busy":"2024-07-24T03:41:14.321974Z","iopub.status.idle":"2024-07-24T03:49:52.415874Z","shell.execute_reply":"2024-07-24T03:49:52.414840Z","shell.execute_reply.started":"2024-07-24T03:41:14.322696Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Assuming you have defined create_vivit_classifier, trainloader, validloader, and testloader\n","\n","EPOCHS = 40\n","\n","def run_experiment():\n","    # Initialize mirrored strategy\n","    strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n","    print(f\"Number of devices: {strategy.num_replicas_in_sync}\")\n","\n","    # Create and compile model within strategy scope\n","    with strategy.scope():\n","        model = create_vivit_classifier(\n","            tubelet_embedder=TubeletEmbedding(\n","                embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE\n","            ),\n","            positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n","        )\n","\n","        optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n","        model.compile(\n","            optimizer=optimizer,\n","            loss=\"sparse_categorical_crossentropy\",\n","            metrics=[\n","                keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n","                keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n","            ],\n","        )\n","\n","    # Callbacks for early stopping and learning rate reduction\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n","\n","    # Train the model\n","    history = model.fit(\n","        trainloader,\n","        epochs=EPOCHS,\n","        validation_data=validloader,\n","        callbacks=[early_stopping],\n","    )\n","\n","    # Evaluate on test set\n","    print(\"--------------------------------------------------\")\n","    _, accuracy, top_5_accuracy = model.evaluate(testloader)\n","    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n","    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n","\n","    return history, model\n","\n","history, model = run_experiment()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T03:24:43.494199Z","iopub.status.busy":"2024-07-24T03:24:43.493821Z","iopub.status.idle":"2024-07-24T03:24:43.552488Z","shell.execute_reply":"2024-07-24T03:24:43.551554Z","shell.execute_reply.started":"2024-07-24T03:24:43.494170Z"},"trusted":true},"outputs":[],"source":["import plotly.graph_objs as go\n","import plotly.subplots as sp\n","\n","# Sample data (replace these with your actual loss values)\n","loss2 = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = list(range(1, len(loss2) + 1))\n","\n","# Create subplots\n","fig = sp.make_subplots(rows=1, cols=2, subplot_titles=('Accuracy', 'Loss'))\n","\n","# Remove accuracy subplot by creating only one subplot for loss\n","fig = sp.make_subplots(rows=1, cols=1, subplot_titles=('Loss',))\n","\n","# Add traces for loss\n","fig.add_trace(\n","    go.Scatter(x=epochs, y=loss2, mode='lines', name='Train Loss', line=dict(color='blue')),\n","    row=1, col=1\n",")\n","fig.add_trace(\n","    go.Scatter(x=epochs, y=val_loss, mode='lines', name='Test Loss', line=dict(color='red')),\n","    row=1, col=1\n",")\n","\n","# Update layout\n","fig.update_layout(\n","    title_text='ViViT Training and Validation Loss',\n","    showlegend=True,\n","    xaxis_title='Epoch',\n","    yaxis_title='Value'\n",")\n","\n","# Update xaxis and yaxis titles for the loss subplot\n","fig.update_xaxes(title_text='Epoch', row=1, col=1)\n","fig.update_yaxes(title_text='Loss', dtick=0.1, row=1, col=1)  # Change dtick to desired step size for Loss\n","\n","# Show figure\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Other metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T03:20:16.317698Z","iopub.status.busy":"2024-07-24T03:20:16.316766Z","iopub.status.idle":"2024-07-24T03:20:18.619610Z","shell.execute_reply":"2024-07-24T03:20:18.618737Z","shell.execute_reply.started":"2024-07-24T03:20:16.317665Z"},"trusted":true},"outputs":[],"source":[" _, accuracy, _ = model.evaluate(testloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T03:23:22.792910Z","iopub.status.busy":"2024-07-24T03:23:22.792497Z","iopub.status.idle":"2024-07-24T03:23:32.000287Z","shell.execute_reply":"2024-07-24T03:23:31.999369Z","shell.execute_reply.started":"2024-07-24T03:23:22.792879Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import classification_report\n","def calculate_metrics(model, testloader):\n","    # Get the true labels and predictions\n","    y_true = []\n","    y_pred = []\n","    label_dict = {0: 'Normal', 1: 'Abnormal'}\n","\n","    for frames, labels in testloader:\n","        preds = model.predict(frames)\n","        y_true.extend(labels.numpy())\n","        y_pred.extend(np.argmax(preds, axis=1))\n","\n","    # Calculate metrics\n","    report = classification_report(y_true, y_pred, target_names=label_dict.values(), output_dict=True)\n","    \n","    precision = report['weighted avg']['precision']\n","    recall = report['weighted avg']['recall']\n","    f1_score = report['weighted avg']['f1-score']\n","\n","    return precision, recall, f1_score\n","\n","\n","precision, recall, f1_score = calculate_metrics(model,testloader)\n","print(f\"Accuracy: {round(accuracy * 100, 2)}%\")\n","print(f'Precision: {round(precision * 100,2)}%')\n","print(f'Recall: {round(recall * 100,2)}%')\n","print(f'f1_score: {round(f1_score * 100,2)}%')"]},{"cell_type":"markdown","metadata":{},"source":["### Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T04:05:53.746964Z","iopub.status.busy":"2024-07-24T04:05:53.746589Z","iopub.status.idle":"2024-07-24T04:06:03.049534Z","shell.execute_reply":"2024-07-24T04:06:03.048556Z","shell.execute_reply.started":"2024-07-24T04:05:53.746933Z"},"trusted":true},"outputs":[],"source":["# Get the true labels\n","true_labels = np.concatenate([y for x, y in testloader], axis=0)\n","\n","# Get the predictions\n","predictions = model.predict(testloader)\n","# predictions = model.predict(validloader)\n","predicted_labels = np.argmax(predictions, axis=1)\n","z = tf.math.confusion_matrix(labels=true_labels, predictions=predicted_labels)\n","\n","# Plot matrix\n","import plotly.express as px\n","fig = px.imshow(z,text_auto=True,color_continuous_scale='blues')\n","\n","fig.update_layout(\n","    title='Confusion Matrix - Test Set',\n","    xaxis_title='Predicted Labels',\n","    yaxis_title='True Labels',\n","    width=800,  # Set width of the figure\n","    height=600,  # Set height of the figure\n",")\n","    \n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Model Before Tuned\n","- Not tuned model\n","\n","NOTE: Accuracy score was good however the fluctuation of the vlidation loss is terrible"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T07:55:40.572458Z","iopub.status.busy":"2024-07-24T07:55:40.572049Z","iopub.status.idle":"2024-07-24T08:07:14.559307Z","shell.execute_reply":"2024-07-24T08:07:14.558314Z","shell.execute_reply.started":"2024-07-24T07:55:40.572430Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Assuming you have defined create_vivit_classifier, trainloader, validloader, and testloader\n","\n","EPOCHS = 40\n","\n","def run_experiment():\n","    # Initialize mirrored strategy\n","    strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n","    print(f\"Number of devices: {strategy.num_replicas_in_sync}\")\n","\n","    # Create and compile model within strategy scope\n","    with strategy.scope():\n","        model = create_vivit_classifier(\n","            tubelet_embedder=TubeletEmbedding(\n","                embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE\n","            ),\n","            positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n","        )\n","\n","        optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n","        model.compile(\n","            optimizer=optimizer,\n","            loss=\"sparse_categorical_crossentropy\",\n","            metrics=[\n","                keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n","                keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n","            ],\n","        )\n","\n","    # Callbacks for early stopping and learning rate reduction\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n","\n","    # Train the model\n","    history = model.fit(\n","        trainloader,\n","        epochs=EPOCHS,\n","        validation_data=validloader,\n","        callbacks=[early_stopping],\n","    )\n","\n","    # Evaluate on test set\n","    print(\"--------------------------------------------------\")\n","    _, accuracy, top_5_accuracy = model.evaluate(testloader)\n","    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n","    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\") #NOTE: If the true label under the top 5 then consider correct prediction\n","\n","    return history, model\n","\n","history, model = run_experiment()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Loss Graph"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T08:10:36.027933Z","iopub.status.busy":"2024-07-24T08:10:36.027510Z","iopub.status.idle":"2024-07-24T08:10:36.093874Z","shell.execute_reply":"2024-07-24T08:10:36.092903Z","shell.execute_reply.started":"2024-07-24T08:10:36.027900Z"},"trusted":true},"outputs":[],"source":["import plotly.graph_objs as go\n","import plotly.subplots as sp\n","\n","# Sample data (replace these with your actual loss values)\n","loss2 = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = list(range(1, len(loss2) + 1))\n","\n","\n","# Remove accuracy subplot by creating only one subplot for loss\n","fig = sp.make_subplots(rows=1, cols=1, subplot_titles=('Loss',))\n","\n","# Add traces for loss\n","fig.add_trace(\n","    go.Scatter(x=epochs, y=loss2, mode='lines', name='Train Loss', line=dict(color='blue')),\n","    row=1, col=1\n",")\n","fig.add_trace(\n","    go.Scatter(x=epochs, y=val_loss, mode='lines', name='Test Loss', line=dict(color='red')),\n","    row=1, col=1\n",")\n","\n","# Update layout\n","fig.update_layout(\n","    title_text='ViViT Training and Validation Loss',\n","    showlegend=True,\n","    xaxis_title='Epoch',\n","    yaxis_title='Value'\n",")\n","\n","# Update xaxis and yaxis titles for the loss subplot\n","fig.update_xaxes(title_text='Epoch', row=1, col=1)\n","fig.update_yaxes(title_text='Loss', dtick=0.1, row=1, col=1)  # Change dtick to desired step size for Loss\n","\n","# Show figure\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Accuracy graph"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T08:15:09.740600Z","iopub.status.busy":"2024-07-24T08:15:09.740170Z","iopub.status.idle":"2024-07-24T08:15:09.747503Z","shell.execute_reply":"2024-07-24T08:15:09.746435Z","shell.execute_reply.started":"2024-07-24T08:15:09.740569Z"},"trusted":true},"outputs":[],"source":["# Average trian and validation accuracy\n","\n","acc2 = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","# Calculate the average accuracy\n","avg_train_acc = np.mean(acc2)\n","avg_val_acc = np.mean(val_acc)\n","\n","print(f\"Average Train Accuracy: {avg_train_acc*100}%\")\n","print(f\"Average Validation Accuracy: {avg_val_acc*100}%\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Hyperparameter tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T09:59:00.989913Z","iopub.status.busy":"2024-07-24T09:59:00.989315Z","iopub.status.idle":"2024-07-24T09:59:00.999615Z","shell.execute_reply":"2024-07-24T09:59:00.998688Z","shell.execute_reply.started":"2024-07-24T09:59:00.989882Z"},"trusted":true},"outputs":[],"source":["# Base line\n","def create_vivit_classifier(\n","    tubelet_embedder,\n","    positional_encoder,\n","    dropout_rate,\n","    input_shape=INPUT_SHAPE,\n","    transformer_layers=NUM_LAYERS,\n","    num_heads=NUM_HEADS,\n","    embed_dim=PROJECTION_DIM,\n","    layer_norm_eps=LAYER_NORM_EPS,\n","    num_classes=NUM_CLASSES,\n","):\n","    # Get the input layer\n","    inputs = layers.Input(shape=input_shape)\n","    # Create patches.\n","    patches = tubelet_embedder(inputs)\n","    # Encode patches.\n","    encoded_patches = positional_encoder(patches)\n","\n","    # Create multiple layers of the Transformer block.\n","    for _ in range(transformer_layers):\n","        # Layer normalization and MHSA\n","        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","        \n","        attention_output = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=dropout_rate\n","        )(x1, x1)\n","\n","\n","        # Skip connection\n","        x2 = layers.Add()([attention_output, encoded_patches])\n","\n","        # Layer Normalization and MLP\n","        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n","        x3 = keras.Sequential(\n","            [\n","                layers.Dense(units=embed_dim * 4, activation=ops.gelu),\n","                layers.Dense(units=embed_dim, activation=ops.gelu),\n","            ]\n","        )(x3)\n","\n","        # Skip connection\n","        encoded_patches = layers.Add()([x3, x2])\n","\n","    # Layer normalization and Global average pooling.\n","    representation = layers.LayerNormalization(epsilon=layer_norm_eps)(encoded_patches)\n","    representation = layers.GlobalAvgPool1D()(representation)\n","\n","    # Classify outputs.\n","    outputs = layers.Dense(units=num_classes, activation=\"softmax\")(representation)\n","\n","    # Create the Keras model.\n","    model = keras.Model(inputs=inputs, outputs=outputs)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T09:59:03.926510Z","iopub.status.busy":"2024-07-24T09:59:03.925672Z","iopub.status.idle":"2024-07-24T09:59:04.214110Z","shell.execute_reply":"2024-07-24T09:59:04.213114Z","shell.execute_reply.started":"2024-07-24T09:59:03.926478Z"},"trusted":true},"outputs":[],"source":["import keras_tuner as kt\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Assuming you have defined create_vivit_classifier, trainloader, validloader, and testloader\n","\n","EPOCHS = 40\n","\n","def build_model(hp):\n","    # Initialize mirrored strategy\n","    strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n","    print(f\"Number of devices: {strategy.num_replicas_in_sync}\")\n","\n","    # Create and compile model within strategy scope\n","    DROPOUT_RATE = hp.Float('dropout_rate', min_value=0.2, max_value=0.8, step=0.1) #NOTE: Total 7\n","    \n","    with strategy.scope():\n","        model = create_vivit_classifier(\n","            tubelet_embedder=TubeletEmbedding(\n","                embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE\n","            ),\n","            positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n","            dropout_rate = DROPOUT_RATE,\n","        )\n","        \n","        LEARNING_RATE = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4, 1e-5]) #NOTE: total 4\n","        optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n","        model.compile(\n","            optimizer=optimizer,\n","            loss=\"sparse_categorical_crossentropy\",\n","            metrics=[\n","                keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n","                keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n","            ],\n","        )\n","\n","    return model\n","#  model = run_experiment()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T09:59:58.974293Z","iopub.status.busy":"2024-07-24T09:59:58.973685Z","iopub.status.idle":"2024-07-24T09:59:59.623826Z","shell.execute_reply":"2024-07-24T09:59:59.623050Z","shell.execute_reply.started":"2024-07-24T09:59:58.974261Z"},"trusted":true},"outputs":[],"source":["tuner = kt.GridSearch(\n","    hypermodel=build_model,\n","    objective=\"val_accuracy\",\n","    max_trials=50,\n","    executions_per_trial=1,\n","    overwrite=True,\n","    directory='my_dir',\n","    project_name=\"ViViT_GridSearch\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T10:00:04.604186Z","iopub.status.busy":"2024-07-24T10:00:04.603292Z","iopub.status.idle":"2024-07-24T10:00:04.609015Z","shell.execute_reply":"2024-07-24T10:00:04.608123Z","shell.execute_reply.started":"2024-07-24T10:00:04.604153Z"},"trusted":true},"outputs":[],"source":["tuner.search_space_summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T09:50:35.423712Z","iopub.status.busy":"2024-07-24T09:50:35.423374Z","iopub.status.idle":"2024-07-24T09:50:35.429811Z","shell.execute_reply":"2024-07-24T09:50:35.428973Z","shell.execute_reply.started":"2024-07-24T09:50:35.423679Z"},"trusted":true},"outputs":[],"source":["tuner.search(trainloader, epochs=40, validation_data=validloader)\n","best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","\n","print(f\"\"\"The hyperparameter grid serachis completed.The optimal parameter for\n","dropput is {best_hps.get('dropout_rate')} and for the learnign rate is {best_hps.get('learning_rate')}\"\"\")"]},{"cell_type":"markdown","metadata":{"id":"f9k9lmcWdP4T"},"source":["# Save model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-24T03:51:52.828002Z","iopub.status.busy":"2024-07-24T03:51:52.824703Z","iopub.status.idle":"2024-07-24T03:51:53.137109Z","shell.execute_reply":"2024-07-24T03:51:53.136298Z","shell.execute_reply.started":"2024-07-24T03:51:52.827955Z"},"id":"Ui0X0cTJdRXc","trusted":true},"outputs":[],"source":["model.save('ViViT_24Jul.keras')"]},{"cell_type":"markdown","metadata":{},"source":["# Demostration"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-07-24T04:05:40.333101Z","iopub.status.busy":"2024-07-24T04:05:40.332473Z","iopub.status.idle":"2024-07-24T04:05:41.258688Z","shell.execute_reply":"2024-07-24T04:05:41.257924Z","shell.execute_reply.started":"2024-07-24T04:05:40.333069Z"},"id":"i0TlEQffdVgl","outputId":"8ead1e2a-6593-42e9-c148-8cb5fa6cc303","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/linzhanyao/opt/anaconda3/envs/tensor_env/lib/python3.10/site-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'tubelet_embedding', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n","  warnings.warn(\n"]}],"source":["model = tf.keras.models.load_model('../Saved_model/ViViT_3July_2.keras')"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step\n","[3.021496e-04 9.996979e-01]\n","Abnormal\n"]}],"source":["import cv2\n","import numpy as np\n","import tensorflow as tf\n","\n","def load_all_frames(video_path):\n","    cap = cv2.VideoCapture(video_path)\n","    if not cap.isOpened():\n","        return {'frames': None, 'frames_dim': None, 'success': False}\n","\n","    frames_dims = []\n","    frames = []\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        h, w, c = frame.shape\n","        frames_dims.append([0, h, w, c])\n","        frame = cv2.resize(frame, (224, 224), interpolation=cv2.INTER_CUBIC)\n","        frames.append(frame)\n","\n","    cap.release()\n","    return {'frames': np.asarray(frames), 'frames_dim': frames_dims, 'success': True}\n","\n","def trim_video_frames(video, max_frame):\n","    '''\n","    Args:\n","        video: video (collection of frames)\n","        max_frame: max number of frames\n","    '''\n","    f, _, _, _ = video.shape\n","    startf = f // 2 - max_frame // 2\n","    return video[startf:startf + max_frame, :, :, :]\n","\n","def preprocess_single_video(video):\n","    video = trim_video_frames(video, 40)\n","    video = tf.image.convert_image_dtype(video, tf.float32)\n","    return video\n","\n","label_dict = {0: 'Normal', 1: 'Abnormal'}\n","video_path = '../Dataset/Test_dataset/abnormal/video_254_flip.avi'\n","\n","load_data = load_all_frames(video_path)\n","if not load_data['success']:\n","    print('Video is corrupt!!')\n","else:\n","    video = load_data['frames']\n","    preprocessed_video = preprocess_single_video(video)\n","    output = model.predict(tf.expand_dims(preprocessed_video, axis=0))[0]\n","    print(output)\n","    pred = np.argmax(output, axis=0)\n","    print(label_dict[pred])\n"]}],"metadata":{"colab":{"collapsed_sections":["PF6UGX5Ku3qx","RXRBDdJ0iGor","FKI0lyPikeBw","42wQWp5PIF6h","WmqqXiqvm1XV","gKCZeRGlLlrq"],"provenance":[],"toc_visible":true},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5325990,"sourceId":8848480,"sourceType":"datasetVersion"},{"datasetId":5337132,"sourceId":8868496,"sourceType":"datasetVersion"},{"datasetId":5436746,"sourceId":9021893,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
